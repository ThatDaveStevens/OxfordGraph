{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26f65668"
      },
      "source": [
        "# LLM Powered PDF Ingestion\n",
        "## Outline\n",
        "1. Data Cleansing\n",
        "2. Prompt Definition\n",
        "3. Entity & Relationship Extraction\n",
        "4. Neo4j Cypher Generation\n",
        "5. Data Ingestion"
      ],
      "id": "26f65668"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Set-up"
      ],
      "metadata": {
        "id": "EnZ9EJN_RdOK"
      },
      "id": "EnZ9EJN_RdOK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting this exercise, prepare your Neo4j Sandbox instance\n",
        "\n",
        "[Neo4j Sandbox](https://neo4j.com/sandbox/)"
      ],
      "metadata": {
        "id": "W-0KeIjbQLqq"
      },
      "id": "W-0KeIjbQLqq"
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "p_ZlsuLtcj8C"
      },
      "outputs": [],
      "source": [
        "#Get your Sandbox credentials and enter them here below\n",
        "\n",
        "connectionUrl = 'bolt://44.203.125.118:7687'\n",
        "username = 'neo4j'\n",
        "password = 'methods-front-booms'"
      ],
      "id": "p_ZlsuLtcj8C"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall openai"
      ],
      "metadata": {
        "id": "2VRQC9vcTVWD"
      },
      "id": "2VRQC9vcTVWD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "61138c34"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install graphdatascience\n",
        "%pip install openai==0.28\n",
        "%pip install python-dotenv\n",
        "%pip install retry\n",
        "%pip install PyPDF2\n",
        "%pip install langchain\n",
        "%pip install sentence-transformers"
      ],
      "id": "61138c34"
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "c2c97f1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from retry import retry\n",
        "import re\n",
        "from string import Template\n",
        "import json\n",
        "import ast\n",
        "import time\n",
        "import pandas as pd\n",
        "from graphdatascience import GraphDataScience\n",
        "import glob\n",
        "from timeit import default_timer as timer\n",
        "from dotenv import load_dotenv"
      ],
      "id": "c2c97f1b"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('open_key')"
      ],
      "metadata": {
        "id": "yY2dniowkyuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b759990-e884-4994-e2fe-0f773bd613af"
      },
      "id": "yY2dniowkyuy",
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "IGjag-WrCa57"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('open_key')\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ],
      "id": "IGjag-WrCa57"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional section to test our connection to the LLM"
      ],
      "metadata": {
        "id": "UFIHaEjmSie9"
      },
      "id": "UFIHaEjmSie9"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain_openai"
      ],
      "metadata": {
        "id": "9PfZuF_OuL-u"
      },
      "id": "9PfZuF_OuL-u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(openai_api_key=userdata.get('open_key'))\n",
        "\n",
        "response = llm.invoke(\"What is Neo4j?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1gp9VoEmuHQ2"
      },
      "id": "1gp9VoEmuHQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d70b41f"
      },
      "source": [
        "## Data Cleansing"
      ],
      "id": "7d70b41f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89595dc"
      },
      "source": [
        "First, let's define a function that can help clean the input data. For the sake of simplicity, lets keep it simple. In the corpus, the data refers to some Figures like scan images. We dont have them and so will remove any such references."
      ],
      "id": "d89595dc"
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "af73c9ce"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  clean = \"\\n\".join([row for row in text.split(\"\\n\")])\n",
        "  clean = re.sub(r'\\(fig[^)]*\\)', '', clean, flags=re.IGNORECASE)\n",
        "  return clean"
      ],
      "id": "af73c9ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5326d17d"
      },
      "source": [
        "Let's take this case sheet and extract entities and relations using LLM"
      ],
      "id": "5326d17d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Source PDF File\n",
        "\n",
        "Example PDF document is the recent \"Building Knowledge Graphs\" book from Jesus Barrasa and Jim Webber"
      ],
      "metadata": {
        "id": "78yFHu_p9mjn"
      },
      "id": "78yFHu_p9mjn"
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = 'ukgovai.pdf'"
      ],
      "metadata": {
        "id": "Dotc13wcVw0a"
      },
      "id": "Dotc13wcVw0a",
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "pdf_reader = PdfReader(pdf)\n",
        "\n",
        "article_txt = \"\"\n",
        "for page in pdf_reader.pages:\n",
        "    article_txt += page.extract_text()"
      ],
      "metadata": {
        "id": "MnVtNj1ZVplW"
      },
      "id": "MnVtNj1ZVplW",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2500, chunk_overlap=200, length_function=len\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(text=article_txt)"
      ],
      "metadata": {
        "id": "OEGyzS-OV4I8"
      },
      "id": "OEGyzS-OV4I8",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "id": "R4F_UQ8kV55J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005e7d85-30d2-426a-9177-00779c46f8b9"
      },
      "id": "R4F_UQ8kV55J",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3236df"
      },
      "source": [
        "## Prompt Definition"
      ],
      "id": "bd3236df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff224199"
      },
      "source": [
        "This is a helper function to talk to the LLM with our prompt and text input"
      ],
      "id": "ff224199"
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "1d8592a3"
      },
      "outputs": [],
      "source": [
        "# GPT-4 Prompt to complete\n",
        "@retry(tries=2, delay=5)\n",
        "def process_gpt(system,\n",
        "                prompt):\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        # engine=\"gpt-3.5-turbo\",\n",
        "        model=\"gpt-4\",\n",
        "        max_tokens=2500,\n",
        "        # Try to be as deterministic as possible\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    )\n",
        "    nlp_results = completion.choices[0].message.content\n",
        "    return nlp_results"
      ],
      "id": "1d8592a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a52639cd"
      },
      "source": [
        "This is a simple prompt to start with. If the processing is very complex, you can also chain the prompts as and when required. I am going to use a single prompt here that helps me to extract the text strictly as per the Entities and Relationships defined. This is a simplification. In the real scenario you have to leverage on Domain experts to define the Ontology systematically and capture the important information. You might also be fine-tuning the model as and when required."
      ],
      "id": "a52639cd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts\n",
        "\n",
        "Our prompt below is deliberately very generic, we are asking the LLM to extract information from the text and categorize it.  The LLM will also enrich the description of the extract information with supporting information from the LLM."
      ],
      "metadata": {
        "id": "8_wwzJVXniAp"
      },
      "id": "8_wwzJVXniAp"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1=\"\"\"From the text below, extract any Entities & Relationships which are of interest,\n",
        "these could be business concepts, technology, people, locations, processes or finanical values\n",
        "\n",
        "0. ALWAYS FINISH THE OUTPUT. Never send partial responses.  You should aim to extract as many entities from the text as possible\n",
        "\n",
        "1. First look for Entities of interest in the text and generate as a comma-separated format similar to the entity type.\n",
        "  The entity label should be defined by the high level category of the entity extracted, look for common terms and groups and use this as the entity label,\n",
        "  replace the label 'Thing' below with a category label.   The name property should be the short name of the extracted entity\n",
        "  'id' property of each entity must be alphanumberic and must be unique among the entities.\n",
        "  You will be referring to this property to define the relationship between each entity\n",
        "\n",
        "  label:'Paper', name:string, summary:string //Title of the article;`name` property is the title of the paper,\n",
        "  in lowercase & camel-case & should always start with an alphabet; summary is a description as defined within openai\n",
        "  label:'Thing', name:string, summary:string //any item of interest within the text,\n",
        "  in lowercase & camel-case & should always start with an alphabet; summary is a description as defined within openai\n",
        "\n",
        "2. Next generate each relationship as a triples of head, relastionship and tail.  To refer the head and tail entity, use their respective 'id' propertry.\n",
        "   Relationship property should be mentioned within brackets as comma-separated.\n",
        "   They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
        "    Relationship types:\n",
        "    Paper|MENTIONS|Thing\n",
        "    Thing|RELATES_TO|Thing\n",
        "\n",
        "    The output should look like :\n",
        "{\n",
        "    \"entities\": [{\"label\":\"Paper\",\"id\":string,\"name\":string,\"summary\":string}],\n",
        "    \"relationships\": [\"paper|MENTIONS_PERSON|businesstrend\"]\n",
        "}\n",
        "\n",
        "Case Sheet:\n",
        "$ctext\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tOcdTD1GffHd"
      },
      "id": "tOcdTD1GffHd",
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_txt"
      ],
      "metadata": {
        "id": "969t1jETFdde"
      },
      "id": "969t1jETFdde",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGwzlESB6TS0"
      },
      "source": [
        "#### Run the analyse"
      ],
      "id": "mGwzlESB6TS0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6a20e1c"
      },
      "source": [
        "Let's run our completion task with our LLM"
      ],
      "id": "a6a20e1c"
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "98cbafb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d14bed6-02a4-4b9d-de2b-417d16c4f863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 110 ms, sys: 15.8 ms, total: 126 ms\n",
            "Wall time: 26.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def run_completion(prompt, results, ctext):\n",
        "    try:\n",
        "      system = \"You are a helpful business analyst who extracts relevant information and store them on a Neo4j Knowledge Graph\"\n",
        "      pr = Template(prompt).substitute(ctext=ctext)\n",
        "      res = process_gpt(system, pr)\n",
        "      results.append(json.loads(res.replace(\"\\'\", \"'\")))\n",
        "      return results\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "prompts = [prompt1]\n",
        "results = []\n",
        "for p in prompts:\n",
        "  results = run_completion(p, results, clean_text(article_txt))\n"
      ],
      "id": "98cbafb5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GJelkUdNs2a"
      },
      "source": [
        "#### Results"
      ],
      "id": "-GJelkUdNs2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AamYyrvGbr66"
      },
      "outputs": [],
      "source": [
        "results"
      ],
      "id": "AamYyrvGbr66"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc40d897"
      },
      "source": [
        "## Neo4j Cypher Generation"
      ],
      "id": "dc40d897"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee2a861f"
      },
      "source": [
        "The entities & relationships we got from the LLM have to be transformed to Cypher so we can ingest into Neo4j"
      ],
      "id": "ee2a861f"
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "7b7fe8c3"
      },
      "outputs": [],
      "source": [
        "#pre-processing results for uploading into Neo4j - helper function:\n",
        "def get_prop_str(prop_dict, _id):\n",
        "    s = []\n",
        "    for key, val in prop_dict.items():\n",
        "      if key != 'label' and key != 'id':\n",
        "         s.append(_id+\".\"+key+' = \"'+str(val).replace('\\\"', '\"').replace('\"', '\\\"')+'\"')\n",
        "    return ' ON CREATE SET ' + ','.join(s)\n",
        "\n",
        "def get_cypher_compliant_var(_id):\n",
        "    return \"_\"+ re.sub(r'[\\W_]', '', _id)\n",
        "\n",
        "def generate_cypher(in_json):\n",
        "    e_map = {}\n",
        "    e_stmt = []\n",
        "    r_stmt = []\n",
        "    e_stmt_tpl = Template(\"($id:$label{id:'$key'})\")\n",
        "    r_stmt_tpl = Template(\"\"\"\n",
        "      MATCH $src\n",
        "      MATCH $tgt\n",
        "      MERGE ($src_id)-[:$rel]->($tgt_id)\n",
        "    \"\"\")\n",
        "    for obj in in_json:\n",
        "      for j in obj['entities']:\n",
        "          props = ''\n",
        "          label = j['label']\n",
        "          id = j['id']\n",
        "          if label == 'Case':\n",
        "                id = 'c'+str(time.time_ns())\n",
        "          elif label == 'Person':\n",
        "                id = 'p'+str(time.time_ns())\n",
        "          varname = get_cypher_compliant_var(j['id'])\n",
        "          stmt = e_stmt_tpl.substitute(id=varname, label=label, key=id)\n",
        "          e_map[varname] = stmt\n",
        "          e_stmt.append('MERGE '+ stmt + get_prop_str(j, varname))\n",
        "\n",
        "      for st in obj['relationships']:\n",
        "          rels = st.split(\"|\")\n",
        "          src_id = get_cypher_compliant_var(rels[0].strip())\n",
        "          rel = rels[1].strip()\n",
        "          tgt_id = get_cypher_compliant_var(rels[2].strip())\n",
        "          stmt = r_stmt_tpl.substitute(\n",
        "              src_id=src_id, tgt_id=tgt_id, src=e_map[src_id], tgt=e_map[tgt_id], rel=rel)\n",
        "\n",
        "          r_stmt.append(stmt)\n",
        "\n",
        "    return e_stmt, r_stmt"
      ],
      "id": "7b7fe8c3"
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "34f74bf0"
      },
      "outputs": [],
      "source": [
        "ent_cyp, rel_cyp = generate_cypher(results)"
      ],
      "id": "34f74bf0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Optional - View the generated Cypher Statements_"
      ],
      "metadata": {
        "id": "7wTjJhaeDE1x"
      },
      "id": "7wTjJhaeDE1x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8zDIAjYcDfH"
      },
      "outputs": [],
      "source": [
        "ent_cyp"
      ],
      "id": "a8zDIAjYcDfH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13588341"
      },
      "source": [
        "### Data Ingestion"
      ],
      "id": "13588341"
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bfe9acfc",
        "outputId": "167ec60e-c18f-4a15-ea11-906f60f00824"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        "gds = GraphDataScience(connectionUrl, auth=(username, password))\n",
        "gds.version()"
      ],
      "id": "bfe9acfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1435e1c9"
      },
      "source": [
        "Ingest the entities"
      ],
      "id": "1435e1c9"
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1f033e",
        "outputId": "92886f24-b863-4599-ab5c-c2588adb8700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31.4 ms, sys: 943 Âµs, total: 32.3 ms\n",
            "Wall time: 1.92 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for e in ent_cyp:\n",
        "    gds.run_cypher(e)\n"
      ],
      "id": "df1f033e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f52ce15b"
      },
      "source": [
        "Ingest relationships now"
      ],
      "id": "f52ce15b"
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "684c1282",
        "outputId": "c66d95f7-31a8-4974-b3e7-19f73a1fb1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 38.7 ms, sys: 3.91 ms, total: 42.6 ms\n",
            "Wall time: 4.96 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for r in rel_cyp:\n",
        "    gds.run_cypher(r)"
      ],
      "id": "684c1282"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m106",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}